{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9f1af4-79c3-4325-92c9-ff954f3af41f",
   "metadata": {},
   "source": [
    "### Transform in Pytorch\n",
    "***A transform is pytorch (usually from torchvision.transforms) is a function that preprocess your data before giving it to the model***\n",
    ">\n",
    "eg:\n",
    "- Convert image to tensor\n",
    "- Normalize pixel values\n",
    "- Resize or crop an image\n",
    "- Apply random flips/rotation (data augmentation)\n",
    "\n",
    "\n",
    "#### Custom dataset\n",
    "Custom Dataset (CSV, NumPy, images on disk, etc.)\n",
    "\n",
    "You load + preprocess the data yourself (scaling, normalizing, converting to tensors).\n",
    "\n",
    "Then you wrap it in a TensorDataset (or a custom Dataset class if needed).\n",
    "\n",
    "Finally, you pass it to a DataLoader to handle batching, shuffling, etc.\n",
    "\n",
    ">import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "> Suppose you loaded your CSV or NumPy\n",
    ">X_train = np.random.rand(100, 20)   # 100 samples, 20 features\n",
    ">y_train = np.random.randint(0, 2, size=(100,))  # binary labels\n",
    "\n",
    "> Convert to tensors\n",
    ">X_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    ">y_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "> Wrap in TensorDataset\n",
    ">train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "> Use DataLoader for batching\n",
    ">train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "#### Built-in Dataset (MNIST, CIFAR10, ImageNet, eg)\n",
    "PyTorch already provides dataset classes in torchvision.datasets.\n",
    "\n",
    "These classes know how to download, load, and apply transforms automatically.\n",
    "\n",
    "You just call them, then wrap in DataLoader.\n",
    "\n",
    ">from torchvision import datasets, transforms\n",
    ">from torch.utils.data import DataLoader\n",
    "\n",
    ">transform = transforms.ToTensor()\n",
    "\n",
    ">train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    ">train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0313d911-326a-4cc3-8e18-75e90df075cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "12\n",
      "Epoch  0\n",
      "Batch 0, Loss: 2.3043\n",
      "Batch 100, Loss: 0.7194\n",
      "Batch 200, Loss: 0.8941\n",
      "Batch 300, Loss: 0.8114\n",
      "Batch 400, Loss: 0.4859\n",
      "Batch 500, Loss: 0.5770\n",
      "Batch 600, Loss: 0.6963\n",
      "Batch 700, Loss: 0.5105\n",
      "Batch 800, Loss: 0.6939\n",
      "Batch 900, Loss: 0.5336\n",
      "Accuracy on test set: 84.42%\n",
      "Epoch  1\n",
      "Batch 0, Loss: 0.6165\n",
      "Batch 100, Loss: 0.4981\n",
      "Batch 200, Loss: 0.5450\n",
      "Batch 300, Loss: 0.4562\n",
      "Batch 400, Loss: 0.4852\n",
      "Batch 500, Loss: 0.2883\n",
      "Batch 600, Loss: 0.8413\n",
      "Batch 700, Loss: 0.5557\n",
      "Batch 800, Loss: 0.3654\n",
      "Batch 900, Loss: 0.4408\n",
      "Accuracy on test set: 86.72%\n",
      "Epoch  2\n",
      "Batch 0, Loss: 0.4205\n",
      "Batch 100, Loss: 0.2880\n",
      "Batch 200, Loss: 0.5156\n",
      "Batch 300, Loss: 0.4210\n",
      "Batch 400, Loss: 0.7224\n",
      "Batch 500, Loss: 0.2304\n",
      "Batch 600, Loss: 0.4319\n",
      "Batch 700, Loss: 0.3529\n",
      "Batch 800, Loss: 0.3728\n",
      "Batch 900, Loss: 0.7228\n",
      "Accuracy on test set: 87.34%\n",
      "Epoch  3\n",
      "Batch 0, Loss: 0.3716\n",
      "Batch 100, Loss: 0.6826\n",
      "Batch 200, Loss: 0.3211\n",
      "Batch 300, Loss: 0.3046\n",
      "Batch 400, Loss: 0.4400\n",
      "Batch 500, Loss: 0.3363\n",
      "Batch 600, Loss: 0.4697\n",
      "Batch 700, Loss: 0.4106\n",
      "Batch 800, Loss: 0.6285\n",
      "Batch 900, Loss: 0.4131\n",
      "Accuracy on test set: 88.74%\n",
      "Epoch  4\n",
      "Batch 0, Loss: 0.3252\n",
      "Batch 100, Loss: 0.3165\n",
      "Batch 200, Loss: 0.2209\n",
      "Batch 300, Loss: 0.5673\n",
      "Batch 400, Loss: 0.4603\n",
      "Batch 500, Loss: 0.4811\n",
      "Batch 600, Loss: 0.4352\n",
      "Batch 700, Loss: 0.4230\n",
      "Batch 800, Loss: 0.3562\n",
      "Batch 900, Loss: 0.4648\n",
      "Accuracy on test set: 88.18%\n",
      "Epoch  5\n",
      "Batch 0, Loss: 0.6112\n",
      "Batch 100, Loss: 0.3661\n",
      "Batch 200, Loss: 0.2799\n",
      "Batch 300, Loss: 0.3408\n",
      "Batch 400, Loss: 0.4960\n",
      "Batch 500, Loss: 0.2517\n",
      "Batch 600, Loss: 0.2195\n",
      "Batch 700, Loss: 0.4737\n",
      "Batch 800, Loss: 0.3946\n",
      "Batch 900, Loss: 0.5212\n",
      "Accuracy on test set: 89.66%\n",
      "Epoch  6\n",
      "Batch 0, Loss: 0.3633\n",
      "Batch 100, Loss: 0.4861\n",
      "Batch 200, Loss: 0.4434\n",
      "Batch 300, Loss: 0.3270\n",
      "Batch 400, Loss: 0.3799\n",
      "Batch 500, Loss: 0.6102\n",
      "Batch 600, Loss: 0.1933\n",
      "Batch 700, Loss: 0.3656\n",
      "Batch 800, Loss: 0.4327\n",
      "Batch 900, Loss: 0.1867\n",
      "Accuracy on test set: 89.80%\n",
      "Epoch  7\n",
      "Batch 0, Loss: 0.2624\n",
      "Batch 100, Loss: 0.3591\n",
      "Batch 200, Loss: 0.4334\n",
      "Batch 300, Loss: 0.3653\n",
      "Batch 400, Loss: 0.3735\n",
      "Batch 500, Loss: 0.3126\n",
      "Batch 600, Loss: 0.2305\n",
      "Batch 700, Loss: 0.4111\n",
      "Batch 800, Loss: 0.3584\n",
      "Batch 900, Loss: 0.3998\n",
      "Accuracy on test set: 89.50%\n",
      "Epoch  8\n",
      "Batch 0, Loss: 0.4385\n",
      "Batch 100, Loss: 0.4825\n",
      "Batch 200, Loss: 0.4802\n",
      "Batch 300, Loss: 0.3736\n",
      "Batch 400, Loss: 0.3856\n",
      "Batch 500, Loss: 0.5453\n",
      "Batch 600, Loss: 0.4088\n",
      "Batch 700, Loss: 0.2529\n",
      "Batch 800, Loss: 0.5019\n",
      "Batch 900, Loss: 0.2212\n",
      "Accuracy on test set: 88.57%\n",
      "Epoch  9\n",
      "Batch 0, Loss: 0.2513\n",
      "Batch 100, Loss: 0.2513\n",
      "Batch 200, Loss: 0.5986\n",
      "Batch 300, Loss: 0.2891\n",
      "Batch 400, Loss: 0.1799\n",
      "Batch 500, Loss: 0.2180\n",
      "Batch 600, Loss: 0.4269\n",
      "Batch 700, Loss: 0.4232\n",
      "Batch 800, Loss: 0.3533\n",
      "Batch 900, Loss: 0.3502\n",
      "Accuracy on test set: 88.49%\n",
      "Epoch  10\n",
      "Batch 0, Loss: 0.6302\n",
      "Batch 100, Loss: 0.5166\n",
      "Batch 200, Loss: 0.4666\n",
      "Batch 300, Loss: 0.2909\n",
      "Batch 400, Loss: 0.2983\n",
      "Batch 500, Loss: 0.4856\n",
      "Batch 600, Loss: 0.2606\n",
      "Batch 700, Loss: 0.6161\n",
      "Batch 800, Loss: 0.6510\n",
      "Batch 900, Loss: 0.1967\n",
      "Accuracy on test set: 90.07%\n",
      "Epoch  11\n",
      "Batch 0, Loss: 0.3546\n",
      "Batch 100, Loss: 0.1663\n",
      "Batch 200, Loss: 0.2604\n",
      "Batch 300, Loss: 0.5364\n",
      "Batch 400, Loss: 0.5672\n",
      "Batch 500, Loss: 0.1681\n",
      "Batch 600, Loss: 0.3840\n",
      "Batch 700, Loss: 0.7944\n",
      "Batch 800, Loss: 0.6322\n",
      "Batch 900, Loss: 0.4750\n",
      "Accuracy on test set: 90.30%\n",
      "Epoch  12\n",
      "Batch 0, Loss: 0.3093\n",
      "Batch 100, Loss: 0.7524\n",
      "Batch 200, Loss: 0.3482\n",
      "Batch 300, Loss: 0.1866\n",
      "Batch 400, Loss: 0.2404\n",
      "Batch 500, Loss: 0.3274\n",
      "Batch 600, Loss: 0.2378\n",
      "Batch 700, Loss: 0.2765\n",
      "Batch 800, Loss: 0.8778\n",
      "Batch 900, Loss: 0.5580\n",
      "Accuracy on test set: 90.98%\n",
      "Epoch  13\n",
      "Batch 0, Loss: 0.2933\n",
      "Batch 100, Loss: 0.2732\n",
      "Batch 200, Loss: 0.3300\n",
      "Batch 300, Loss: 0.2049\n",
      "Batch 400, Loss: 0.3560\n",
      "Batch 500, Loss: 0.3086\n",
      "Batch 600, Loss: 0.3060\n",
      "Batch 700, Loss: 0.4210\n",
      "Batch 800, Loss: 0.5092\n",
      "Batch 900, Loss: 0.5373\n",
      "Accuracy on test set: 90.06%\n",
      "Epoch  14\n",
      "Batch 0, Loss: 0.2230\n",
      "Batch 100, Loss: 0.3324\n",
      "Batch 200, Loss: 0.4492\n",
      "Batch 300, Loss: 0.3778\n",
      "Batch 400, Loss: 0.3946\n",
      "Batch 500, Loss: 0.4526\n",
      "Batch 600, Loss: 0.3375\n",
      "Batch 700, Loss: 0.5241\n",
      "Batch 800, Loss: 0.3348\n",
      "Batch 900, Loss: 0.4985\n",
      "Accuracy on test set: 90.14%\n",
      "Epoch  15\n",
      "Batch 0, Loss: 0.3976\n",
      "Batch 100, Loss: 0.3025\n",
      "Batch 200, Loss: 0.3346\n",
      "Batch 300, Loss: 0.1563\n",
      "Batch 400, Loss: 0.4291\n",
      "Batch 500, Loss: 0.6589\n",
      "Batch 600, Loss: 0.2338\n",
      "Batch 700, Loss: 0.3731\n",
      "Batch 800, Loss: 0.1786\n",
      "Batch 900, Loss: 0.3276\n",
      "Accuracy on test set: 90.42%\n",
      "Epoch  16\n",
      "Batch 0, Loss: 0.5946\n",
      "Batch 100, Loss: 0.3337\n",
      "Batch 200, Loss: 0.4329\n",
      "Batch 300, Loss: 0.1569\n",
      "Batch 400, Loss: 0.2719\n",
      "Batch 500, Loss: 0.3198\n",
      "Batch 600, Loss: 0.3676\n",
      "Batch 700, Loss: 0.4031\n",
      "Batch 800, Loss: 0.5576\n",
      "Batch 900, Loss: 0.2211\n",
      "Accuracy on test set: 91.37%\n",
      "Epoch  17\n",
      "Batch 0, Loss: 0.4728\n",
      "Batch 100, Loss: 0.3462\n",
      "Batch 200, Loss: 0.2341\n",
      "Batch 300, Loss: 0.4123\n",
      "Batch 400, Loss: 0.2210\n",
      "Batch 500, Loss: 0.3985\n",
      "Batch 600, Loss: 0.3422\n",
      "Batch 700, Loss: 0.4471\n",
      "Batch 800, Loss: 0.6055\n",
      "Batch 900, Loss: 0.5820\n",
      "Accuracy on test set: 90.38%\n",
      "Epoch  18\n",
      "Batch 0, Loss: 0.4597\n",
      "Batch 100, Loss: 0.3092\n",
      "Batch 200, Loss: 0.5915\n",
      "Batch 300, Loss: 0.4266\n",
      "Batch 400, Loss: 0.4412\n",
      "Batch 500, Loss: 0.2272\n",
      "Batch 600, Loss: 0.5181\n",
      "Batch 700, Loss: 0.2593\n",
      "Batch 800, Loss: 0.2142\n",
      "Batch 900, Loss: 0.3184\n",
      "Accuracy on test set: 91.57%\n",
      "Epoch  19\n",
      "Batch 0, Loss: 0.2436\n",
      "Batch 100, Loss: 0.2780\n",
      "Batch 200, Loss: 0.6960\n",
      "Batch 300, Loss: 0.4142\n",
      "Batch 400, Loss: 0.3735\n",
      "Batch 500, Loss: 0.2948\n",
      "Batch 600, Loss: 0.5389\n",
      "Batch 700, Loss: 0.4022\n",
      "Batch 800, Loss: 0.5087\n",
      "Batch 900, Loss: 0.2476\n",
      "Accuracy on test set: 89.31%\n",
      "Epoch  20\n",
      "Batch 0, Loss: 0.3458\n",
      "Batch 100, Loss: 0.2246\n",
      "Batch 200, Loss: 0.3471\n",
      "Batch 300, Loss: 0.3617\n",
      "Batch 400, Loss: 0.6236\n",
      "Batch 500, Loss: 0.2935\n",
      "Batch 600, Loss: 0.1697\n",
      "Batch 700, Loss: 0.3283\n",
      "Batch 800, Loss: 0.2370\n",
      "Batch 900, Loss: 0.4965\n",
      "Accuracy on test set: 90.98%\n",
      "Epoch  21\n",
      "Batch 0, Loss: 0.3944\n",
      "Batch 100, Loss: 0.2136\n",
      "Batch 200, Loss: 0.1714\n",
      "Batch 300, Loss: 0.4207\n",
      "Batch 400, Loss: 0.1440\n",
      "Batch 500, Loss: 0.2706\n",
      "Batch 600, Loss: 0.2494\n",
      "Batch 700, Loss: 0.1918\n",
      "Batch 800, Loss: 0.4749\n",
      "Batch 900, Loss: 0.3324\n",
      "Accuracy on test set: 91.06%\n",
      "Epoch  22\n",
      "Batch 0, Loss: 0.3249\n",
      "Batch 100, Loss: 0.4049\n",
      "Batch 200, Loss: 0.2908\n",
      "Batch 300, Loss: 0.3021\n",
      "Batch 400, Loss: 0.4558\n",
      "Batch 500, Loss: 0.2609\n",
      "Batch 600, Loss: 0.3814\n",
      "Batch 700, Loss: 0.1166\n",
      "Batch 800, Loss: 0.2696\n",
      "Batch 900, Loss: 0.5826\n",
      "Accuracy on test set: 91.33%\n",
      "Epoch  23\n",
      "Batch 0, Loss: 0.2775\n",
      "Batch 100, Loss: 0.1459\n",
      "Batch 200, Loss: 0.6965\n",
      "Batch 300, Loss: 0.3332\n",
      "Batch 400, Loss: 0.5061\n",
      "Batch 500, Loss: 0.3136\n",
      "Batch 600, Loss: 0.7035\n",
      "Batch 700, Loss: 0.2565\n",
      "Batch 800, Loss: 0.2875\n",
      "Batch 900, Loss: 0.2769\n",
      "Accuracy on test set: 91.48%\n",
      "Epoch  24\n",
      "Batch 0, Loss: 0.1133\n",
      "Batch 100, Loss: 0.2771\n",
      "Batch 200, Loss: 0.2452\n",
      "Batch 300, Loss: 0.2072\n",
      "Batch 400, Loss: 0.2163\n",
      "Batch 500, Loss: 0.2772\n",
      "Batch 600, Loss: 0.7235\n",
      "Batch 700, Loss: 0.3703\n",
      "Batch 800, Loss: 0.2206\n",
      "Batch 900, Loss: 0.3159\n",
      "Accuracy on test set: 91.03%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "# Define the transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),              # Resize 28x18 -> 32x32\n",
    "    transforms.RandomRotation(10),            # random rotate (-10 degree to 10 degree)\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Random flip left-right\n",
    "    transforms.ToTensor(),                    # Comvert image to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))      # normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "num_cpu_cores = os.cpu_count()\n",
    "print(num_cpu_cores)\n",
    "\n",
    "# Load Dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64, num_workers=num_cpu_cores)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=64, num_workers=num_cpu_cores)\n",
    "\n",
    "# Model \n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32*32, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "model = SimpleNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Training Loop\n",
    "\n",
    "for epoch in range(25):\n",
    "    \n",
    "    model.train()\n",
    "    print('Epoch ', epoch)\n",
    "\n",
    "    for idx, (image, labels) in enumerate(train_loader):\n",
    "        image, labels = image.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass = prediction and loss\n",
    "        output = model(image)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 100 ==0:\n",
    "            print(f\"Batch {idx}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Testing\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            out = model(images)\n",
    "            _, predicted = torch.max(out, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f9813-dda7-465f-a8a6-8590855c4490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01cd438-1f2a-4ddf-a088-7014389ab4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (custom)",
   "language": "python",
   "name": "custom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
